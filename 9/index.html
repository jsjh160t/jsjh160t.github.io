<!DOCTYPE html>
<html>
  <head>
    <title>人體姿態估測成果展示(靜態_視訊擷取影像預測)</title>
    <!-- 相關依賴套件載入 -->
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs-core"></script>
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs-converter"></script>    
    <!-- 本章節採用tfjs，因此載入TF.js backend -->
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs-backend-webgl"></script>    
    <!-- 載入手勢辨識模型 -->
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow-models/pose-detection"></script>
  </head>
  <body>
    <!-- 用於呈現分析結果canvas -->
    <canvas id='canvas1' height="0" width="0"></canvas>
    
    <script>
      // 宣告canvas 物件
      const canvas = document.getElementById('canvas1');
      // 宣告canvas 繪圖物件
      var ctx = canvas.getContext('2d')
      
      // webcam 攝影
      async function takePhoto() {
        //方法1.等待~~確保 TensorFlow.js 在進行其他操作之前已經初始化。
        //await tf.ready();
        //方法2.等待 TensorFlow.js 初始化，確保後端已經設置好並且準備就緒。
        await tf.setBackend('webgl');
        
        // 讀取模型
        const detectorConfig = {modelType: poseDetection.movenet.modelType.SINGLEPOSE_LIGHTNING};
        const detector = await poseDetection.createDetector(poseDetection.SupportedModels.MoveNet, detectorConfig);
      
        const div = document.createElement('div'); // 空行
        const capture = document.createElement('button'); // 攝影按鈕
        capture.textContent = 'Capture'; // 攝影按鈕文字
        div.appendChild(capture);
      
        const video = document.createElement('video'); // 宣告影片物件
        video.style.display = 'block';
        const stream = await navigator.mediaDevices.getUserMedia({video: true}); // 宣告串流物件
      
        document.body.appendChild(div);
        div.appendChild(video);
        video.srcObject = stream; // 使影片物件顯示串流內容
        await video.play();
      
        // 調整Video Element 大小
        //google.colab.output.setIframeHeight(document.documentElement.scrollHeight, true);
      
        // 等待點擊攝影按鈕
        await new Promise((resolve) => capture.onclick = resolve);
      
        // canvas 繪製底圖
        canvas.width = video.videoWidth;
        canvas.height = video.videoHeight;
        ctx.drawImage(video, 0, 0);
      
        // 停止 webcamera
        stream.getVideoTracks()[0].stop();
        div.remove();
      
        // 模型推論分析
        const poses = await detector.estimatePoses(canvas1);
        console.log(poses)
      
        // 人體關節點註解文字顏色
        ctx.strokeStyle = "red";
        // 人體關節點註解文字大小&字體
        ctx.font = "20px Arial";
        // 繪製模型分析結果
        keypoints = poses[0].keypoints
        for (var i = 0; i < keypoints.length; i++) {
            console.log(keypoints[i]);
      
            // 關節點pixel-wise位置
            x = keypoints[i].x
            y = keypoints[i].y
      
            // 關節點類別
            name = keypoints[i].name
      
            // 圈選關節點估測位置
            ctx.beginPath();
            ctx.arc(x, y, 20, 0, 2 * Math.PI);
            ctx.stroke();
      
            // 繪製關節點文字註解
            ctx.fillText(name, x+30, y);
        }
      }
      
      takePhoto()
    </script>
  </body>
</html>
