<!DOCTYPE html>
<html>
  <head>
    <title>人體姿態估測成果展示(動態_視訊擷取影像預測)</title>
    <!-- 相關依賴套件載入 -->
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs-core"></script>
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs-converter"></script>
    <!-- 本章節採用tfjs，因此載入TF.js backend -->
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs-backend-webgl"></script>
    <!-- 載入手勢辨識模型 -->
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow-models/pose-detection"></script>
    </head>
    <body>
      <!-- 用於呈現分析結果canvas -->
      <canvas id='canvas1' height="0" width="0"></canvas>

      <script>
        // 宣告canvas 物件
        const canvas = document.getElementById('canvas1');
        // 宣告canvas 繪圖物件
        var ctx = canvas.getContext('2d')

        // webcam 攝影
        async function takePhoto() {
          // 讀取模型
          const detectorConfig = {modelType: poseDetection.movenet.modelType.SINGLEPOSE_LIGHTNING};
          const detector = await poseDetection.createDetector(poseDetection.SupportedModels.MoveNet, detectorConfig);

          const div = document.createElement('div'); // 空行
          const capture = document.createElement('button'); // 攝影按鈕
          capture.textContent = 'Capture'; // 攝影按鈕文字
          div.appendChild(capture);

          const video = document.createElement('video'); // 宣告影片物件
          video.style.display = 'block';
          const stream = await navigator.mediaDevices.getUserMedia({video: true}); // 宣告串流物件

          document.body.appendChild(div);
          div.appendChild(video);
          video.srcObject = stream; // 使影片物件顯示串流內容
          await video.play();

          // 調整Video Element 大小
          //google.colab.output.setIframeHeight(document.documentElement.scrollHeight, true);

          // 等待點擊攝影按鈕
          await new Promise((resolve) => capture.onclick = resolve);

          // canvas 繪製底圖
          canvas.width = video.videoWidth;
          canvas.height = video.videoHeight;
          ctx.drawImage(video, 0, 0);

          // 停止 webcamera
          stream.getVideoTracks()[0].stop();
          div.remove();

          // 模型推論分析
          const poses = await detector.estimatePoses(canvas1);
          console.log(poses)

          // 人體關節點註解文字顏色
          ctx.strokeStyle = "red";
          // 人體關節點註解文字大小&字體
          ctx.font = "20px Arial";
          // 繪製模型分析結果
          keypoints = poses[0].keypoints
          for (var i = 0; i < keypoints.length; i++) {
              console.log(keypoints[i]);

              // 關節點pixel-wise位置
              x = keypoints[i].x
              y = keypoints[i].y

              // 關節點類別
              name = keypoints[i].name

              // 圈選關節點估測位置
              ctx.beginPath();
              ctx.arc(x, y, 20, 0, 2 * Math.PI);
              ctx.stroke();

              // 繪製關節點文字註解
              ctx.fillText(name, x+30, y);
          }
        }

        takePhoto()
      </script>
  </body>
</html>