<!DOCTYPE html>
<html>
  <head>
    <title>人體姿態估測成果展示(動態_視訊動態預測)</title>
    <!-- 相關依賴套件載入 -->
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs-core"></script>
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs-converter"></script>
    <!-- 本章節採用tfjs，因此載入TF.js backend -->
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs-backend-webgl"></script>
    <!-- 載入手勢辨識模型 -->
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow-models/pose-detection"></script>
    <!-- 隱藏html video -->
    <style>
        video{
            visibility: hidden;
        }
    </style>
  </head>
  <body>
    <!-- 呈現結果的canvas -->
    <canvas id="detect_result"></canvas>
    <!-- 串流video -->
    <video autoplay playsinline muted id="webcam" ></video>

    <script>
      async function app() {
        //方法1.等待~~確保 TensorFlow.js 在進行其他操作之前已經初始化。
        //await tf.ready();
        //方法2.等待 TensorFlow.js 初始化，確保後端已經設置好並且準備就緒。
        await tf.setBackend('webgl');
        
        // 讀取模型
        const detectorConfig = {modelType: poseDetection.movenet.modelType.SINGLEPOSE_LIGHTNING};
        const detector = await poseDetection.createDetector(poseDetection.SupportedModels.MoveNet, detectorConfig);

        const webcamElement = document.getElementById('webcam'); // 宣告影片物件

        // 宣告canvas物件
        const canvas = document.getElementById('detect_result');
        const ctx = canvas.getContext('2d');

        let showResult = async function () {
          // 模型推論分析
          const poses = await detector.estimatePoses(canvas);
          console.log(poses)

          // canvas 繪製底圖
          canvas.width = webcamElement.videoWidth;
          canvas.height = webcamElement.videoHeight;
          ctx.drawImage(webcamElement, 0, 0);

          // 人體關節點註解文字顏色
          ctx.strokeStyle = "red";
          // 人體關節點註解文字大小&字體
          ctx.font = "20px Arial";
          // 繪製模型分析結果
          if (poses.length>0){
            keypoints = poses[0].keypoints
            for (var i = 0; i < keypoints.length; i++) {
                console.log(keypoints[i]);

                // 關節點pixel-wise位置
                x = keypoints[i].x
                y = keypoints[i].y

                // 關節點類別
                name = keypoints[i].name

                // 圈選關節點估測位置
                ctx.beginPath();
                ctx.arc(x, y, 20, 0, 2 * Math.PI);
                ctx.stroke();

                // 繪製關節點文字註解
                ctx.fillText(name, x+30, y);
            }
          }

          // 設定每偵顯示秒數
          setTimeout(function () {
              showResult();
          }, 300);
        }
        let setupWebcam = function () {
            return new Promise((resolve, reject) => {
                const navigatorAny = navigator;
                navigator.getUserMedia = navigator.getUserMedia ||
                    navigatorAny.webkitGetUserMedia || navigatorAny.mozGetUserMedia ||
                    navigatorAny.msGetUserMedia;
                if (navigator.getUserMedia) {
                    navigator.getUserMedia({
                            video: true
                        },
                        (stream) => {
                            webcamElement.srcObject = stream;
                            webcamElement.addEventListener('loadeddata', () => resolve(),
                                false);
                        },
                        (err) => reject(err));
                } else {
                    reject("getUserMedia failed");
                }
            });
        }
        setupWebcam().then(
            () => {
                showResult();
            },
            (err) => {
                console.log(err);
            }
        )
      }
      app();
    </script>
  </body>
</html>